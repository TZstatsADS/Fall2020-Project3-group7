---
title: "Prediction on Facial Expression using proposed algorithms"
author: "Siyu Duan, Xingying Feng, Depeng Kong, Xinyuan Peng, Natalie Williams"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
editor_options:
  chunk_output_type: console
---

```{r eval=FALSE}
if(!require("EBImage")){
  install.packages("BiocManager")
}

if(!require("R.matlab")){
  install.packages("R.matlab")
}
if(!require("readxl")){
  install.packages("readxl")
}

if(!require("dplyr")){
  install.packages("dplyr")
}
if(!require("readxl")){
  install.packages("readxl")
}


if(!require("caret")){
  install.packages("caret")
}

if(!require("glmnet")){
  install.packages("glmnet")
}

if(!require("WeightedROC")){
  install.packages("WeightedROC")
}

if(!require("AUC")){
  install.packages("AUC")
}

if(!require("e1071")){
  install.packages("e1071")
}


if(!require("tibble")){
  install.packages("tibble")
}

if(!require("ROSE")){
  install.packages("ROSE")
}

if(!require("tidyverse")){
  install.packages("tidyverse")
}

library(R.matlab)
library(readxl)
library(dplyr)
library(BiocManager)
library(ggplot2)
library(caret)
library(glmnet)
library(WeightedROC)
library(OpenImageR)
library(AUC)
library(e1071)
library(randomForest)
library(xgboost)
library(tibble)
library(ROSE)
library(tidyverse)
```

### Step 0 set work directories
```{r wkdir, eval=FALSE}
set.seed(2020)
#set working directory to the doc folder on your laptop
setwd("~/Documents/GitHub/Fall2020-Project3-group_7/doc")
#\setwd("~/GitHub/Fall2020-Project3-group_7/doc")
#setwd("./")
```

Provide directories for training images. Training images and Training fiducial points will be in different subfolders. 
```{r}
train_dir <- "~/Downloads/train_set/"
#train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="") 
```

### Step 1: set up controls for evaluation experiments.

```{r exp_setup}
run.cv <- F # run cross-validation on the training set
sample.reweight <- TRUE # run sample reweighting in model training
K <- 5  # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test <- TRUE # run evaluation on an independent test set
run.feature.test <- TRUE # process features for test set
```


### Step 2: import data and train-test split 
```{r}
#train-test split
info <- read.csv(train_label_path)
n <- nrow(info)
n_train <- round(n*(4/5), 0)
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index, train_idx)
```

Fiducial points are stored in matlab format. In this step, we read them and store them in a list.
```{r read fiducial points}
#function to read fiducial points
#input: index
#output: matrix of fiducial points corresponding to the index
n_files <- length(list.files(train_image_dir))

readMat.matrix <- function(index){
     return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}

#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)

save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
```

### Step 3: construct features and responses

  + `feature.R`
  + Input: list of images or fiducial point
  + Output: an RData file that contains extracted features and corresponding responses

```{r feature}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
  tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
  save(dat_train, file="../output/feature_train.RData")
}else{
  load(file="../output/feature_train.RData")
}

tm_feature_test <- NA
if(run.feature.test){
  tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
  save(dat_test, file="../output/feature_test.RData")
}else{
  load(file="../output/feature_test.RData")
}
# transfer label column from factor to numeric
dat_train$label <- as.numeric(dat_train$label)-1
dat_test$label <- as.numeric(dat_test$label)-1
```

###Step 3.1: Rebalancing training data-Bootstrap Random Over-Sampling Examples Technique (ROSE)

```{r}
dat_train_balanced_rose<-ROSE(label~., dat_train,seed=2020)$data
dat_train_balanced_rose$label <- as.numeric(dat_train_balanced_rose$label)
table(dat_train_balanced_rose$label)
```


### Step 4: Train baseline model with training features and responses
##### Step 4.1: Baseline Model - Gradient Boosting Machine(GBM) with default setting of parameters
###### Step 4.1(a): Train GBM with default setting of parameters
The defalut parameters are:

+ distribution = "bernoulli" (if the response has only 2 unique values, bernoulli is assumed)
+ n.trees = 100, 
+ shrinkage = 0.1, 
+ interaction.depth = 1,
+ cv. fold = 3

```{r train_GBM_base}
# load model built-in from lib
source("../lib/train_GBM_base.R") 

# fit train data
tm_train_GBM_base = NA
tm_train_GBM_base<- system.time(fit_train_GBM_base <- train_GBM_base(features= dat_train_balanced_rose))
save(fit_train_GBM_base , file="../output/train_GBM_base.RData")
```


###### Step 4.1(b): Test GBM with default setting of parameters
We predicted the test data and evaluated the performance of default GBM model.
```{r test_gbm}
### load models built
source("../lib/test_GBM.R")
### predict test data
tm_test_GBM_base=NA
if(run.test){
  load(file="../output/train_GBM_base.RData")
  tm_test_GBM_base <- system.time(prob_pred_GBM_base <- test_GBM(fit_train_GBM_base, dat_test))
}
pred_test_GBM_base = round(test_GBM(fit_train_GBM_base, dat_test),digit=0)
accu_test_GBM_base <- mean(dat_test$label == pred_test_GBM_base)

pred_train_GBM_base = round(test_GBM(fit_train_GBM_base,dat_train_balanced_rose),digit=0)
accu_train_GBM_base <- mean(dat_train_balanced_rose$label == pred_train_GBM_base)
```

Calculate weightedAUC for rebalanced data
```{r}
label_test <- as.integer(dat_test$label)
weight_test <- rep(NA, length(label_test))
for (v in unique(label_test)){
  weight_test[label_test == v] = 0.5 * length(label_test) / length(label_test[label_test == v])
}

pred_test_GBM_base<-as.integer(pred_test_GBM_base)
accu_GBM_base <- sum(weight_test * (pred_test_GBM_base== label_test)) / sum(weight_test)
tpr.fpr <- WeightedROC(prob_pred_GBM_base, label_test, weight_test)
auc_GBM_base <- WeightedAUC(tpr.fpr)
```

###### Step 4.1(c): Summary of GBM model
```{r}
cat("The AUC of model:  GBM_base", "is", auc_GBM_base, ".\n")
cat("The accuracy of model: GBM_base on balanced training data", "is", accu_train_GBM_base*100, "%.\n")
cat("The accuracy of model: GBM_base on imbalanced testing data", "is",  accu_test_GBM_base*100, "%.\n")
cat("The accuracy of model: GBM_base on balanced testing data", "is", accu_GBM_base*100, "%.\n")
cat("Time for training model GBM_baseline = ", tm_train_GBM_base[1], "s \n")
cat("Time for testing model GBM_baseline = ",tm_test_GBM_base[1], "s \n")
```




### Step 5: Other advanced models
#### Step 5.1: SVM
###### Step 5.1(a): Train SVM with with tuning parameters
```{r SVM}
source("../lib/svm.R")
# Tune SVM
set.seed(2020)
#opt.svm <- svm_tune(dat_train_balanced_rose[sample(1:nrow(dat_train_balanced_rose), 
#                                                   round(nrow(dat_train_balanced_rose)/4),
#                                                   replace = F), ])
# bestgamma = opt.svm$best.parameters$gamma
# bestcost = opt.svm$best.parameters$cost

# Train SVM
tm_svm_train <- system.time(
  svm_fit <- svm (dat_train_balanced_rose$label ~ .,
         data = dat_train_balanced_rose,
         gamma = 0.001,
         cost = 0.021,
         kernel = "linear",
         cross = 10
    )
)
save(svm_fit, file = "../output/train_svm.RData")

svm_train_pred <- svm_test(svm_fit, dat_train_balanced_rose)
aucc_train_svm = mean(round(svm_train_pred) == dat_test$label)
```

###### Step 5.1(b): Test SVM with with tuning parameters
```{r}
tm_svm_test=NA
if(run.test){
  load(file="../output/train_svm.RData")
  tm_svm_test <- system.time(
  svm_pred <- svm_test(svm_fit, dat_test))
}

# Calculate Accuracy
aucc_test_svm = mean(round(svm_pred) == dat_test$label) # unweighted
accu_svm <- sum(weight_test * (round(svm_pred) == label_test)) / sum(weight_test)

# Calculate ROC AUC
tpr.fpr <- WeightedROC(svm_pred, label_test, weight_test)
auc_svm <- WeightedAUC(tpr.fpr)
```

###### Step 5.1(c): Summary of SVM
```{r}

cat("The AUC of model after reweighting:  SVM", "is", auc_svm, ".\n")
cat("The accuracy of model: SVM on balanced training data", "is", aucc_train_svm*100, "%.\n")
cat("The accuracy of model: SVM on imbalanced testing data", "is", aucc_test_svm*100, "%.\n")
cat("The accuracy of model: SVM on balanced testing data", "is", accu_svm*100, "%.\n")
cat("Time for training model SVM = ", tm_svm_train[1], "s \n")
cat("Time for testing model SVM = ",tm_svm_test[1], "s \n")
```




### Step 6:Conclusion
###### Step 6.1：Summarize Running Time for all models
Prediction performance matters, so does the running times for constructing features and for training the model, especially when the computation resource is limited. 
```{r running_time}

feature_time<-tibble(
  feature_extr_train_time=tm_feature_train[1], 
  feature_extr_test_time=tm_feature_test[1]
)


 result_table<-tribble(
  ~model, ~training_time, ~testing_time, ~accuracy_balanced_training, ~accuracy_balanced_testing,~accuracy_imbalanced_testing, ~auc_testing,
  "GBM baseline", tm_train_GBM_base[1], tm_test_GBM_base[1],accu_train_GBM_base*100, accu_GBM_base*100,accu_test_GBM_base*100, auc_GBM_base,
  "SVM", tm_svm_train[1], tm_svm_test[1], aucc_train_svm*100,accu_svm*100, aucc_test_svm*100,auc_svm
)
result_table
```


###### Step 6.2：Base line and Final advanced model comparision 
```{r}
cat("Time for training feature extraction = ", tm_feature_train[1], "s \n")
cat("Time for testing feature extraction = ",tm_feature_test[1], "s \n")

#Baseline model：  GBM 
cat("The AUC of model:  GBM_base", "is", auc_GBM_base, ".\n")
cat("The accuracy of model: GBM_base on balanced training data", "is", accu_train_GBM_base*100, "%.\n")
cat("The accuracy of model: GBM_base on imbalanced testing data", "is",  accu_test_GBM_base*100, "%.\n")
cat("The accuracy of model: GBM_base on balanced testing data", "is", accu_GBM_base*100, "%.\n")
cat("Time for training model GBM_baseline = ", tm_train_GBM_base[1], "s \n")
cat("Time for testing model GBM_baseline = ",tm_test_GBM_base[1], "s \n")

#Advanced model：SVM 
cat("The AUC of model after reweighting:  SVM", "is", auc_svm, ".\n")
cat("The accuracy of model: SVM on balanced training data", "is", aucc_train_svm*100, "%.\n")
cat("The accuracy of model: SVM on imbalanced testing data", "is", aucc_test_svm*100, "%.\n")
cat("The accuracy of model: SVM on balanced testing data", "is", accu_svm*100, "%.\n")
cat("Time for training model SVM = ", tm_svm_train[1], "s \n")
cat("Time for testing model SVM = ",tm_svm_test[1], "s \n")



```



```{r}

label_prediction<-tibble("Index"= test_idx, "GBM_base"=pred_test_GBM_base, "SVM"=round(svm_pred))
  

write.csv(label_prediction, file="../output/label_prediction.csv")

```
###Reference
- Du, S., Tao, Y., & Martinez, A. M. (2014). Compound facial expressions of emotion. Proceedings of the National Academy of Sciences, 111(15), E1454-E1462.













