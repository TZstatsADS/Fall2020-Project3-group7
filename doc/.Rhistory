library(OpenImageR)
library(AUC)
library(e1071)
library(randomForest)
library(xgboost)
library(tibble)
library(ROSE)
library(ggplot2)
set.seed(2020)
setwd("~/Documents/GitHub/Fall2020-Project3-group_7/doc")
#\setwd("~/GitHub/Fall2020-Project3-group_7/doc")
#setwd("./")
train_dir <- "~/Downloads/train_set/"
#train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
run.cv <- F # run cross-validation on the training set
sample.reweight <- TRUE # run sample reweighting in model training
K <- 5  # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test <- TRUE # run evaluation on an independent test set
run.feature.test <- TRUE # process features for test set
#train-test split
info <- read.csv(train_label_path)
n <- nrow(info)
n_train <- round(n*(4/5), 0)
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index, train_idx)
#function to read fiducial points
#input: index
#output: matrix of fiducial points corresponding to the index
n_files <- length(list.files(train_image_dir))
readMat.matrix <- function(index){
return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}
#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
save(dat_train, file="../output/feature_train.RData")
}else{
load(file="../output/feature_train.RData")
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
save(dat_test, file="../output/feature_test.RData")
}else{
load(file="../output/feature_test.RData")
}
# transfer label column from factor to numeric
dat_train$label <- as.numeric(dat_train$label)-1
dat_test$label <- as.numeric(dat_test$label)-1
dat_train_balanced_rose<-ROSE(label~., dat_train,seed=2020)$data
table(dat_train_balanced_rose$label)
# load model built-in from ib
source("../lib/train_GBM_base.R")
# fit train data
tm_train_GBM_base = NA
tm_train_GBM_base1 <- system.time(fit_train_GBM_base <- train_GBM_base(features= dat_train_balanced_rose))
save(fit_train_GBM_base , file="../output/train_GBM_base.RData")
### load models built
source("../lib/test_GBM.R")
### predict test data
tm_test_GBM_base=NA
if(run.test){
load(file="../output/train_GBM_base.RData")
tm_test_GBM_base <- system.time(prob_pred_GBM_base <- test_GBM(fit_train_GBM_base, dat_test))
}
pred_test_GBM_base = round(test_GBM(fit_train_GBM_base, dat_test),digit=0)
accu_test_GBM_base <- mean(dat_test$label == pred_test_GBM_base)
cat("The AUC of model:  GBM_base", "is", auc_GBM_base, ".\n")
cat("The accuracy of model: GBM_base on imbalanced testing data", "is",  accu_test_GBM_base*100, "%.\n")
cat("The accuracy of model: GBM_base on balanced testing data", "is", accu_GBM_base*100, "%.\n")
cat("Time for training model GBM_baseline = ", tm_train_GBM_base[1], "s \n")
cat("Time for testing model GBM_baseline = ",tm_test_GBM_base[1], "s \n")
tm_train_GBM_base<- system.time(fit_train_GBM_base <- train_GBM_base(features= dat_train_balanced_rose))
save(fit_train_GBM_base , file="../output/train_GBM_base.RData")
cat("The AUC of model:  GBM_base", "is", auc_GBM_base, ".\n")
label_test <- as.integer(dat_test$label)
weight_test <- rep(NA, length(label_test))
for (v in unique(label_test)){
weight_test[label_test == v] = 0.5 * length(label_test) / length(label_test[label_test == v])
}
pred_test_GBM_base<-as.integer(pred_test_GBM_base)
accu_GBM_base <- sum(weight_test * (pred_test_GBM_base== label_test)) / sum(weight_test)
tpr.fpr <- WeightedROC(prob_pred_GBM_base, label_test, weight_test)
auc_GBM_base <- WeightedAUC(tpr.fpr)
cat("The AUC of model:  GBM_base", "is", auc_GBM_base, ".\n")
cat("The accuracy of model: GBM_base on imbalanced testing data", "is",  accu_test_GBM_base*100, "%.\n")
cat("The accuracy of model: GBM_base on balanced testing data", "is", accu_GBM_base*100, "%.\n")
cat("Time for training model GBM_baseline = ", tm_train_GBM_base[1], "s \n")
# load model built-in from lib
source("../lib/train_GBM_improved.R")
# fit train data
tm_train_GBM_improved = NA
tm_train_GBM_improved <- system.time(fit_train_GBM_improved <- train_GBM_improved(features= dat_train_balanced_rose))
save(fit_train_GBM_improved , file="../output/train_GBM_improved.RData")
### load models built
source("../lib/test_GBM.R")
### predict test data
tm_test_GBM_improved=NA
if(run.test){
load(file="../output/train_GBM_improved.RData")
tm_test_GBM_improved <- system.time(prob_pred_GBM_improved<- test_GBM(fit_train_GBM_improved, dat_test))
}
pred_test_GBM_improved = round(test_GBM(fit_train_GBM_improved, dat_test),digit=0)
accu_test_GBM_improved <- mean(dat_test$label == pred_test_GBM_improved)
label_pred_GBM_improved<-as.integer(pred_test_GBM_improved)
accu_BGM_improved <- sum(weight_test * (label_pred_GBM_improved == label_test)) / sum(weight_test)
#prob_pred <- lable_pred
tpr.fpr <- WeightedROC(prob_pred_GBM_improved, label_test, weight_test)
auc_GBM_improved <- WeightedAUC(tpr.fpr)
cat("The AUC of model after reweighting:  GBM_improved", "is", auc_GBM_improved, ".\n")
cat("The accuracy of model: Improved GBM on imbalanced testing data", accu_test_GBM_improved*100, "%.\n")
cat("The accuracy of model: Improved GBM on balanced testing data", "is", accu_BGM_improved*100, "%.\n")
cat("Time for training model GBM_improved = ", tm_train_GBM_improved[1], "s \n")
cat("Time for testing model GBM_improved = ",tm_test_GBM_improved[1], "s \n")
labels <- dat_train$label
ts_labels <- dat_test$label
new_tr <- model.matrix(~.+0,data = dat_train_balanced_rose[,-which(names(dat_train_balanced_rose) %in% c("label"))])
new_ts <- model.matrix(~.+0,data = dat_train_balanced_rose[,-which(names(dat_train_balanced_rose) %in% c("label"))])
#labels <- as.numeric(labels)-1
ts_labels <- as.numeric(ts_labels)-1
dtrain <- xgb.DMatrix(data = new_tr,label = labels)
dtest <- xgb.DMatrix(data = new_ts,label=ts_labels)
xgb_train_time=NA
xgb_train_time<-system.time(xgb <- xgboost (data = dtrain, booster = "gbtree", objective = "binary:logistic", eta=0.5, gamma=0.1, max_depth=4, min_child_weight=1, subsample=1, colsample_bytree=1, nrounds = 5))
save(xgb, file = "../output/train_xgb.RData")
xgb_test_time = NA
if(run.test){
load(file="../output/train_xgb.RData")
xgb_test_time<-system.time(xgb_pred <- predict(xgb, dtest))
}
err <- mean(as.numeric(xgb_pred > 0.5) != dat_test$label)
aucc_test_xgb<- (1-err)*100
labels <- dat_train_balanced_rose$label
ts_labels <- dat_test$label
new_tr <- model.matrix(~.+0,data = dat_train_balanced_rose[,-which(names(dat_train_balanced_rose) %in% c("label"))])
new_ts <- model.matrix(~.+0,data = dat_train_balanced_rose[,-which(names(dat_train_balanced_rose) %in% c("label"))])
#labels <- as.numeric(labels)-1
ts_labels <- as.numeric(ts_labels)-1
dtrain <- xgb.DMatrix(data = new_tr,label = labels)
dtest <- xgb.DMatrix(data = new_ts,label=ts_labels)
dim(ts_labels)
ts_labels
ts_labels <- dat_test$label+1
ts_labels
ts_labels <- dat_test$label
ts_labels
labels <- dat_train_balanced_rose$label
ts_labels <- dat_test$label
ts_labels
new_tr <- model.matrix(~.+0,data = dat_train_balanced_rose[,-which(names(dat_train_balanced_rose) %in% c("label"))])
new_ts <- model.matrix(~.+0,data = dat_train_balanced_rose[,-which(names(dat_train_balanced_rose) %in% c("label"))])
#labels <- as.numeric(labels)-1
ts_labels <- as.numeric(ts_labels)-1
ts_labels
#labels <- as.numeric(labels)-1
#ts_labels <- as.numeric(ts_labels)-1
dtrain <- xgb.DMatrix(data = new_tr,label = labels)
dtest <- xgb.DMatrix(data = new_ts,label=ts_labels)
count(new_ts)
dim(new_ts)
labels <- dat_train_balanced_rose$label
ts_labels <- dat_test$label
new_tr <- model.matrix(~.+0,data = dat_train_balanced_rose[,-which(names(dat_train_balanced_rose) %in% c("label"))])
new_ts <- model.matrix(~.+0,data = dat_test[,-which(names(dat_test) %in% c("label"))])
#labels <- as.numeric(labels)-1
ts_labels <- as.numeric(ts_labels)-1
dtrain <- xgb.DMatrix(data = new_tr,label = labels)
dtest <- xgb.DMatrix(data = new_ts,label=ts_labels)
xgb_train_time=NA
xgb_train_time<-system.time(xgb <- xgboost (data = dat_train_balanced_rose, booster = "gbtree", objective = "binary:logistic", eta=0.5, gamma=0.1, max_depth=4, min_child_weight=1, subsample=1, colsample_bytree=1, nrounds = 5))
save(xgb, file = "../output/train_xgb.RData")
xgb_train_time<-system.time(xgb <- xgboost (data = dtrain, booster = "gbtree", objective = "binary:logistic", eta=0.5, gamma=0.1, max_depth=4, min_child_weight=1, subsample=1, colsample_bytree=1, nrounds = 5))
save(xgb, file = "../output/train_xgb.RData")
xgb_test_time = NA
if(run.test){
load(file="../output/train_xgb.RData")
xgb_test_time<-system.time(xgb_pred <- predict(xgb, dtest))
}
err <- mean(as.numeric(xgb_pred > 0.5) != dat_test$label)
aucc_test_xgb<- (1-err)*100
label_pred_xgb<-as.integer(round(xgb_pred))
accu_xgb <- sum(weight_test * (label_pred_xgb == label_test)) / sum(weight_test)
#prob_pred <- lable_pred
tpr.fpr <- WeightedROC(xgb_pred, label_test, weight_test)
auc_xgb <- WeightedAUC(tpr.fpr)
cat("The AUC of model after reweighting:  XGB", "is", auc_xgb, ".\n")
cat("The accuracy of model: XGB on imbalanced testing data", "is", aucc_test_xgb, "%.\n")
cat("The accuracy of model: XGB on balanced testing data", "is", accu_xgb*100, "%.\n")
cat('The time of training xgb model is: ', xgb_train_time[1], 's \n')
cat('The time of testing xgb model is: ', xgb_test_time[1], 's \n')
# Tune SVM
set.seed(2020)
# Train SVM
tm_svm_train <- system.time(
svm_fit <- svm_train(dat_train_balanced_rose, gamma=0.001, cost=0.001, kernel="linear",cross=10)
)
source("../lib/svm.R")
# Train SVM
tm_svm_train <- system.time(
svm_fit <- svm_train(dat_train_balanced_rose, gamma=0.001, cost=0.001, kernel="linear",cross=10)
)
source("../lib/svm.R")
# Tune SVM
set.seed(2020)
# Train SVM
tm_svm_train <- system.time(
svm_fit <- svm (factor(dat_train_balanced_rose$label) ~ .,
data = dat_train_balanced_rose,
gamma = 0.001,
cost = 0.001,
kernel = "linear",
cross = 10
)
)
save(svm_fit, file = "../output/train_svm.RData")
tm_svm_test=NA
if(run.test){
load(file="../output/train_svm.RData")
tm_svm_test <- system.time(
svm_pred <- svm_test(svm_fit, dat_test))
}
# Calculate Accuracy
aucc_test_svm = mean(svm_pred == dat_test$label) # unweighted
accu_svm <- sum(weight_test * (svm_pred == label_test)) / sum(weight_test)
# Calculate ROC AUC
tpr.fpr <- WeightedROC(as.numeric(svm_pred)-1, label_test, weight_test)
auc_svm <- WeightedAUC(tpr.fpr)
cat("The AUC of model after reweighting:  SVM", "is", auc_svm, ".\n")
cat("The accuracy of model: SVM on imbalanced testing data", "is", aucc_test_svm*100, "%.\n")
cat("The accuracy of model: SVM on balanced testing data", "is", accu_svm*100, "%.\n")
cat("Time for training model SVM = ", tm_svmTrain[1], "s \n")
cat("Time for testing model SVM = ",tm_svmTest[1], "s \n")
cat("Time for training model SVM = ", tm_svm_train[1], "s \n")
cat("Time for testing model SVM = ",tm_svm_tes[1], "s \n")
cat("Time for testing model SVM = ",tm_svm_test[1], "s \n")
source("../lib/rand_f.R")
# training rf
tm_rfTrain <- system.time(
rf_fit <- rf_train(dat_train_balanced_rose,
mtry = 2002)
)
if(!require("tidyverse")){
install.packages("tidyverse")
}
library(tidyverse)
feature_time<-tibble(
feature_extr_train_time=tm_feature_train[1],
feature_extr_test_time=tm_feature_test[1]
)
feature_time
save(feature_time, file = "../output/feature_extraction_time.RData")
#training time for RF: tm_rfTrain[1]
#Testing time for RF : tm_rfTest[1]
running_time<-tribble(
~model, ~training_time, ~testing_time,
"GBM baseline", tm_train_GBM_base[1], tm_test_GBM_base[1],
"GBM improved", tm_train_GBM_improved[1], tm_test_GBM_improved[1],
"XGB",xgb_train_time[1], xgb_test_time[1],
"Random Forest", 8694.217, 0.62,
"SVM", tm_svmTrain[1], tm_svmTest[1]
)
#training time for RF: tm_rfTrain[1]
#Testing time for RF : tm_rfTest[1]
running_time<-tribble(
~model, ~training_time, ~testing_time,
"GBM baseline", tm_train_GBM_base[1], tm_test_GBM_base[1],
"GBM improved", tm_train_GBM_improved[1], tm_test_GBM_improved[1],
"XGB",xgb_train_time[1], xgb_test_time[1],
"Random Forest", 8694.217, 0.62,
"SVM", tm_svm_train[1], tm_svm_test[1]
)
running_time
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= "The type of time", value="time in seconds")
p1
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= "The type of time", value="time in seconds")%>%
group_by(model)%>%
ggplot2(aes(x=model, y="time in seconds", color="The type of time")) +
geom_line()+
theme_light()
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= "The type of time", value="time in seconds")%>%
group_by(model)%>%
ggplot(aes(x=model, y="time in seconds", color="The type of time")) +
geom_line()+
theme_light()
p1
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= type, value=time)%>%
group_by(model)%>%
ggplot(aes(x=model, y=time, color=type)) +
geom_line()+
theme_light()
p1
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= type, value=time)%>%
ggplot(aes(x=model, y=time, color=type)) +
geom_line()+
theme_light()
p1
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= type, value=time)%>%
ggplot(aes(x=model, y=time, color=type)) +
geom_point()+
geom_line()+
theme_light()
p1
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= type, value=time)%>%
ggplot(aes(x=model, y=time, color=type, goup=1)) +
geom_point()+
geom_line()+
theme_light()
p1
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= type, value=time)%>%
ggplot(aes(x=model,y=time, color=type, group=1)) +
geom_line()+
theme_light()
p1
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= type, value=time)%>%
ggplot(aes(x=model,y=time, color=type, group=1)) +
geom_bar()+
theme_light()
p1
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= type, value=time)%>%
ggplot(aes(x=model,y=time,group=1)) +
geom_line()+
facet_warp(.~type)+
theme_light()
#running time plot
p1<-running_time%>%
gather(training_time:testing_time, key= type, value=time)%>%
ggplot(aes(x=model,y=time,group=1)) +
geom_line()+
facet_grid(.~type)+
theme_light()
p1
accu_rf_test*100<-77
accu_rf*100 <-49.35897
accu_rf_test<-77
accu_rf<-49.35897
Accuracy_imbalanced<-tribble(
~model, ~accuracy(%),
"GBM baseline", accu_test_GBM_base*100,
"GBM improved",accu_test_GBM_improved*100,
"XGB",accu_test_xgb*100,
"Random Forest", accu_rf_test ,
"SVM", accu_test_svm*100
)
Accuracy_imbalanced<-tribble(
~model, ~accuracy(%),
"GBM baseline", accu_test_GBM_base*100,
"GBM improved",accu_test_GBM_improved*100,
"XGB",accu_test_xgb*100,
"Random Forest", accu_rf_test ,
"SVM", accu_test_svm*100
)
Accuracy_imbalanced<-tribble(
~model, ~accuracy,
"GBM baseline", accu_test_GBM_base*100,
"GBM improved",accu_test_GBM_improved*100,
"XGB",accu_test_xgb*100,
"Random Forest", accu_rf_test ,
"SVM", accu_test_svm*100
)
err <- mean(as.numeric(xgb_pred > 0.5) != dat_test$label)
aucc_test_xgb<- (1-err)*100
Accuracy_imbalanced<-tribble(
~model, ~accuracy,
"GBM baseline", accu_test_GBM_base*100,
"GBM improved",accu_test_GBM_improved*100,
"XGB",accu_test_xgb*100,
"Random Forest", accu_rf_test ,
"SVM", accu_test_svm*100
)
Accuracy_imbalanced<-tribble(
~model, ~accuracy,
"GBM baseline", accu_test_GBM_base*100,
"GBM improved",accu_test_GBM_improved*100,
"XGB",aucc_test_xgb*100,
"Random Forest", accu_rf_test ,
"SVM", accu_test_svm*100
)
Accuracy_imbalanced<-tribble(
~model, ~accuracy,
"GBM baseline", accu_test_GBM_base*100,
"GBM improved",accu_test_GBM_improved*100,
"XGB",aucc_test_xgb*100,
"Random Forest", accu_rf_test ,
"SVM", aucc_test_svm*100
)
Accuracy_imbalanced
aucc_test_xgb
Accuracy_imbalanced<-tribble(
~model, ~accuracy,
"GBM baseline", accu_test_GBM_base*100,
"GBM improved",accu_test_GBM_improved*100,
"XGB",aucc_test_xgb,
"Random Forest", accu_rf_test ,
"SVM", aucc_test_svm*100
)
Accuracy_imbalanced
Accuracy_balanced<-tribble(
~model, ~accuracy,
"GBM baseline", accu_GBM_base*100,
"GBM improved",accu_GBM_improved*100,
"XGB",accu_xgb*100,
"Random Forest", accu_rf,
"SVM", aucc_svm*100
)
accu_GBM_improved <- sum(weight_test * (label_pred_GBM_improved == label_test)) / sum(weight_test)
Accuracy_balanced<-tribble(
~model, ~accuracy,
"GBM baseline", accu_GBM_base*100,
"GBM improved",accu_GBM_improved*100,
"XGB",accu_xgb*100,
"Random Forest", accu_rf,
"SVM", aucc_svm*100
)
Accuracy_balanced<-tribble(
~model, ~accuracy,
"GBM baseline", accu_GBM_base*100,
"GBM improved",accu_GBM_improved*100,
"XGB",accu_xgb*100,
"Random Forest", accu_rf,
"SVM", accu_svm*100
)
Accuracy_balanced
Accuracy_imbalanced<-tribble(
~model, ~accuracy_imbalanced,
"GBM baseline", accu_test_GBM_base*100,
"GBM improved",accu_test_GBM_improved*100,
"XGB",aucc_test_xgb,
"Random Forest", accu_rf_test ,
"SVM", aucc_test_svm*100
)
Accuracy_imbalanced
Accuracy_balanced<-tribble(
~model, ~accuracy_balanced,
"GBM baseline", accu_GBM_base*100,
"GBM improved",accu_GBM_improved*100,
"XGB",accu_xgb*100,
"Random Forest", accu_rf,
"SVM", accu_svm*100
)
Accuracy_balanced
auc_rf <-0.5264747
auc<-tribble(
~model, ~auc_testing_set,
"GBM baseline", auc_GBM_base*100,
"GBM improved",auc_GBM_improved*100,
"XGB",auc_xgb,
"Random Forest", auc_rf*100,
"SVM", auc_svm*100
)
auc
auc<-tribble(
~model, ~auc_testing_set,
"GBM baseline", auc_GBM_base,
"GBM improved",auc_GBM_improved,
"XGB",auc_xgb,
"Random Forest", auc_rf,
"SVM", auc_svm
)
auc
Table<-running_time%>%
full_join(Accuracy_balanced, by="model")%>%
full_join(auc, by="model")
Table
cat("Time for training model GBM_baseline = ", tm_feature_train[1], "s \n")
cat("Time for testing model GBM_baseline = ",tm_feature_test[1], "s \n")
cat("Time for training feature extraction = ", tm_feature_train[1], "s \n")
cat("Time for testing feature extraction = ",tm_feature_test[1], "s \n")
Table%>%filter(model %in% c("GBM baseline","SVM"))
cat("Time for training feature extraction = ", tm_feature_train[1], "s \n")
cat("Time for testing feature extraction = ",tm_feature_test[1], "s \n")
#Baseline model：  GBM
cat("The AUC of model:  GBM_base", "is", auc_GBM_base, ".\n")
cat("The accuracy of model: GBM_base on imbalanced testing data", "is",  accu_test_GBM_base*100, "%.\n")
cat("The accuracy of model: GBM_base on balanced testing data", "is", accu_GBM_base*100, "%.\n")
cat("Time for training model GBM_baseline = ", tm_train_GBM_base[1], "s \n")
cat("Time for testing model GBM_baseline = ",tm_test_GBM_base[1], "s \n")
#Advanced model：SVM
cat("The AUC of model after reweighting:  SVM", "is", auc_svm, ".\n")
cat("The accuracy of model: SVM on imbalanced testing data", "is", aucc_test_svm*100, "%.\n")
cat("The accuracy of model: SVM on balanced testing data", "is", accu_svm*100, "%.\n")
cat("Time for training model SVM = ", tm_svm_train[1], "s \n")
cat("Time for testing model SVM = ",tm_svm_test[1], "s \n")
Table%>%filter(model %in% c("GBM baseline","SVM"))
save(Table, file = "../output/summary_table.RData")
